{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# STA130 Week 01 Homework"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> #### Homework Chat Logs:\n",
    "> - Question 1: *https://chatgpt.com/share/f02e67f3-b267-4f07-9986-12cc71849307*\n",
    "> \n",
    "> - Question 2-3: *https://chatgpt.com/share/a5ee8942-7a7b-4573-b21f-cce4d89afd5f*\n",
    "> \n",
    "> - Question 4-5: *https://chatgpt.com/share/3b997b5b-fa52-4b7a-b6f1-20618c705840*\n",
    "> \n",
    "> - Question 6: *https://chatgpt.com/share/27a9c262-c579-4c0f-8b6a-ed8bfba2ac98*\n",
    "> \n",
    "> - Question 7: *https://chatgpt.com/share/5b41149a-1c86-4ca6-84d0-68955d2b9def*\n",
    "> \n",
    "> - Question 8: *https://chatgpt.com/share/67bfed28-7390-4177-971e-1ce63f7f35fc*, *https://chatgpt.com/share/97d63dd0-bb0c-4f8d-ad55-f3866e8091bc*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Pick one of the datasets from the ChatBot session(s) of the `TUT demo` (or from your own ChatBot session if you wish) and use the code produced through the ChatBot interactions to import the data and confirm that the dataset has missing values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 200,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "body        0\n",
       "category    0\n",
       "id          0\n",
       "rating      0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 200,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# feel free to just use the following if you prefer...\n",
    "import pandas as pd\n",
    "url = \"https://raw.githubusercontent.com/taivop/joke-dataset/master/stupidstuff.json\"\n",
    "\n",
    "df = pd.read_json(url) # Global variable\n",
    "df.isna().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Start a new ChatBot session with an initial prompt introducing the dataset you're using and request help to determine how many columns and rows of data a `pandas` DataFrame has."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 1. use code provided in your ChatBot session to print out the number of rows and columns of the dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 201,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of the dataset: (3773, 4)\n",
      "Number of entries: 3773\n",
      "Number of columns: 4\n",
      "Columns: ['body', 'category', 'id', 'rating']\n",
      "Example entry:\n",
      "body        A blackjack dealer and a player with a thirtee...\n",
      "category                                             Children\n",
      "id                                                          1\n",
      "rating                                                   2.63\n",
      "Name: 0, dtype: object\n"
     ]
    }
   ],
   "source": [
    "# Display the shape of the dataset\n",
    "print(f\"Shape of the dataset: {df.shape}\")\n",
    "\n",
    "# Display the number of rows and columns\n",
    "print(f\"Number of entries: {df.shape[0]}\")\n",
    "print(f\"Number of columns: {df.shape[1]}\")\n",
    "\n",
    "# Display the column names\n",
    "print(f\"Columns: {df.columns.tolist()}\")\n",
    "\n",
    "# Show an example entry to understand the structure of the data\n",
    "print(f\"Example entry:\\n{df.iloc[0]}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 2. write your own general definitions of the meaning of \"observations\" and \"variables\" based on asking the ChatBot to explain these terms in the context of your dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`Observations` are the individual data points or rows in my dataset. For example, each observation represents a single joke entry in my dataset.\n",
    "\n",
    "`Variables` are the attributes or columns pertaning to each characteristic of an observation in my dataset. For example, variables include body, category, id, and rating in my dataset."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. Ask the ChatBot how you can provide simple summaries of the columns in the dataset and use the suggested code to provide these summaries for your dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 202,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>rating</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>3773.000000</td>\n",
       "      <td>3773.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>1887.000000</td>\n",
       "      <td>3.284363</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>1089.315611</td>\n",
       "      <td>1.199279</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>944.000000</td>\n",
       "      <td>2.330000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>1887.000000</td>\n",
       "      <td>3.090000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>2830.000000</td>\n",
       "      <td>4.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>3773.000000</td>\n",
       "      <td>5.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                id       rating\n",
       "count  3773.000000  3773.000000\n",
       "mean   1887.000000     3.284363\n",
       "std    1089.315611     1.199279\n",
       "min       1.000000     0.000000\n",
       "25%     944.000000     2.330000\n",
       "50%    1887.000000     3.090000\n",
       "75%    2830.000000     4.000000\n",
       "max    3773.000000     5.000000"
      ]
     },
     "execution_count": 202,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Summary statistics for numeric columns\n",
    "df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 203,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Miscellaneous      831\n",
       "Insults            196\n",
       "Men                190\n",
       "Religious          152\n",
       "Computers          150\n",
       "Women              144\n",
       "Yo Mama            141\n",
       "Political          141\n",
       "Animals            131\n",
       "Light Bulbs        120\n",
       "Blonde Jokes       111\n",
       "Business           104\n",
       "Medical            101\n",
       "Family, Parents     96\n",
       "Heaven and Hell     91\n",
       "Bar Jokes           87\n",
       "Children            82\n",
       "Money               82\n",
       "Holidays            69\n",
       "Police Jokes        67\n",
       "School              62\n",
       "Sports              61\n",
       "Military            58\n",
       "Sex                 54\n",
       "Lawyers             50\n",
       "Love & Romance      48\n",
       "Crazy Jokes         43\n",
       "Marriage            37\n",
       "Aviation            35\n",
       "Idiots              31\n",
       "Farmers             29\n",
       "One Liners          28\n",
       "Redneck             27\n",
       "Old Age             22\n",
       "Science             18\n",
       "Office Jokes        18\n",
       "Deep Thoughts       14\n",
       "Food Jokes          13\n",
       "Blind Jokes         11\n",
       "State Jokes         10\n",
       "Music                9\n",
       "Ethnic Jokes         8\n",
       "English              1\n",
       "Name: category, dtype: int64"
      ]
     },
     "execution_count": 203,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Value counts for a specific column (for non-numeric data)\n",
    "df['category'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4. If the dataset you're using has (a) non-numeric variables and (b) missing values in numeric variables, explain (perhaps using help from a ChatBot if needed) the discrepancies between size of the dataset given by `df.shape` and what is reported by `df.describe()` with respect to (a) the number of columns it analyzes and (b) the values it reports in the \"count\" column."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The reason there are discrepanices between the number of entries in certain columns such as `age` and in `deck` is because...\n",
    "\n",
    "&nbsp;&nbsp;&nbsp;&nbsp;a. the `DataFrame` object cannot be jagged and must have a rectangular shape. Every row/column must have the same length as every other row/column.\n",
    "\n",
    "&nbsp;&nbsp;&nbsp;&nbsp;b. `mdf.describe()` doesn't count NaN values(*e.i. missing values*) and skips them when calculating `mean`, `std`, etc."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 204,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape: (891, 15)\n",
      "Description:\n",
      "         survived      pclass         age       sibsp       parch        fare\n",
      "count  891.000000  891.000000  714.000000  891.000000  891.000000  891.000000\n",
      "mean     0.383838    2.308642   29.699118    0.523008    0.381594   32.204208\n",
      "std      0.486592    0.836071   14.526497    1.102743    0.806057   49.693429\n",
      "min      0.000000    1.000000    0.420000    0.000000    0.000000    0.000000\n",
      "25%      0.000000    2.000000   20.125000    0.000000    0.000000    7.910400\n",
      "50%      0.000000    3.000000   28.000000    0.000000    0.000000   14.454200\n",
      "75%      1.000000    3.000000   38.000000    1.000000    0.000000   31.000000\n",
      "max      1.000000    3.000000   80.000000    8.000000    6.000000  512.329200\n",
      "# Of Missing Entries:\n",
      "survived         0\n",
      "pclass           0\n",
      "sex              0\n",
      "age            177\n",
      "sibsp            0\n",
      "parch            0\n",
      "fare             0\n",
      "embarked         2\n",
      "class            0\n",
      "who              0\n",
      "adult_male       0\n",
      "deck           688\n",
      "embark_town      2\n",
      "alive            0\n",
      "alone            0\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# Using recommended dataset since my dataset has no missing values.\n",
    "\n",
    "import pandas as pd\n",
    "url = \"https://raw.githubusercontent.com/mwaskom/seaborn-data/master/titanic.csv\"\n",
    "\n",
    "tdf = pd.read_csv(url)\n",
    "\n",
    "print(f\"Shape: {tdf.shape}\")\n",
    "\n",
    "print(f\"Description:\\n{tdf.describe()}\")\n",
    "\n",
    "print(f\"# Of Missing Entries:\\n{tdf.isna().sum()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5. Use your ChatBot session to help understand the difference between the following and then provide your own paraphrasing summarization of that difference.\n",
    "\n",
    "- an \"attribute\", such as `df.shape` which does not end with `()`\n",
    "- and a \"method\", such as `df.describe()` which does end with `()` "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`df.shape` is a pre-calculated value when the `DataFrame` object is created. It represents an attribute in the `DataFrame` class and is saved in memory.\n",
    "\n",
    "`df.describe()` is a method in the `DataFrame` class and returns a `Series` or `DataFrame` object, representing a *\"summary statistics of the `Series` or `DataFrame` provided\"* ([Pandas Docs](https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.describe.html)). Because it is a method and thus a function, it runs a written block of code to calculate the summary everytime it is called."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6. The `df.describe()` method provides the 'count', 'mean', 'std', 'min', '25%', '50%', '75%', and 'max' summary statistics for each variable it analyzes. Give the definitions (perhaps using help from the ChatBot if needed) of each of these summary statistics."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The `df.describe()` method provides a statistical summary of numerical variables in a `DataFrame` object.\n",
    "\n",
    "The following are the definitions of each figure given in the statistical summary...\n",
    "1. **Count**: The number of non-NaN values in each column. It gives the total number of data points available for each variable.\n",
    "\n",
    "2. **Mean**: The average of the values in each column. It is the sum of all values divided by the number of values.\n",
    "\n",
    "3. **Std**: The standard deviation of the values in each column. It measures the amount of variation from the mean. It is the square root of the variance, which is the sum of squared differences between values and the mean divided by the number of values minus 1.\n",
    "\n",
    "4. **Min**: The smallest value in each column.\n",
    "\n",
    "5. **25%**: The 25th percentile value (also known as the first quartile). It is the value below which 25% of the data points in a column fall.\n",
    "\n",
    "6. **50%**: The 50th percentile value (also known as the median). It is the middle value of the data points.\n",
    "\n",
    "7. **75%**: The 75th percentile value (also known as the third quartile). It is the value below which 75% of the data points in a column fall.\n",
    "\n",
    "8. **Max**: The largest value in each column.\n",
    "\n",
    "`df.describe()` skips any NaN values when calculating the previous figures. This is why sometimes **count** and the **# of rows** don't match."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 7. Missing data can be considered \"across rows\" or \"down columns\".  Consider how `df.dropna()` or `del df['col']` should be applied to most efficiently use the available non-missing data in your dataset and briefly answer the following questions in your own words."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 1. Provide an example of a \"use case\" in which using `df.dropna()` might be preferred over using `del df['col']`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "An instance `df.dropna()` may be preferred over `del df['col']` is when columns are uniformly filled out but certain rows have missing data.\n",
    "\n",
    "**For example:** In an online form, people are sometimes lazy or rush through filling out the form. It would be helpful to remove their entries as they aren't helpful/accurate."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 2. Provide an example of \"the opposite use case\" in which using `del df['col']` might be preferred over using `df.dropna()`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "An instance `df.dropna()` may be preferred over `del df['col']` is when most columns are filled out but there certain columns which are missing significant amounts of data.\n",
    "\n",
    "**For example:** When filling out an online form, people often skip the same questions over and over again leading to certain columns being largely empty. It would be helpful to remove an entire column as there isn't enough data to draw any useful conclusions."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 3. Discuss why applying `del df['col']` before `df.dropna()` when both are used together could be important."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Removing columns missing large amounts of data first would potientially lead to more rows being preserved when `df.dropna()` is run.\n",
    "\n",
    "**For example:** If most people fill out the entire online form but skip the same question, it wouldn't make sense to delete almost every entry just because one column is mostly empty."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "##### 4. Remove all missing data from one of the datasets you're considering using some combination of `del df['col']` and/or `df.dropna()` and give a justification for your approach, including a \"before and after\" report of the results of your approach for your dataset."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the previous dataset for Question 4, I noticed many columns have more than 100 entries while some columns only have a few. By setting a threshold for which columns are deleted then calling `dropna()`, I minimized the amount of data that was deleted."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 205,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initial Shape: (891, 15)\n",
      "Initial Missing Data Summary:\n",
      "survived         0\n",
      "pclass           0\n",
      "sex              0\n",
      "age            177\n",
      "sibsp            0\n",
      "parch            0\n",
      "fare             0\n",
      "embarked         2\n",
      "class            0\n",
      "who              0\n",
      "adult_male       0\n",
      "deck           688\n",
      "embark_town      2\n",
      "alive            0\n",
      "alone            0\n",
      "dtype: int64\n",
      "Initial Shape: (182, 15)\n",
      "Initial Missing Data Summary:\n",
      "survived       0\n",
      "pclass         0\n",
      "sex            0\n",
      "age            0\n",
      "sibsp          0\n",
      "parch          0\n",
      "fare           0\n",
      "embarked       0\n",
      "class          0\n",
      "who            0\n",
      "adult_male     0\n",
      "deck           0\n",
      "embark_town    0\n",
      "alive          0\n",
      "alone          0\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "clean_mdf = tdf.copy()\n",
    "\n",
    "# Initial state: Shape and missing data summary\n",
    "print(f\"Initial Shape: {clean_mdf.shape}\")\n",
    "\n",
    "missing_columns = clean_mdf.isna().sum()\n",
    "print(f\"Initial Missing Data Summary:\\n{missing_columns}\")\n",
    "\n",
    "# Step 1: Delete columns which are missing 100 or more entries.\n",
    "threshold = 100\n",
    "for name, mdata in missing_columns.items():\n",
    "\tif mdata >= threshold:\n",
    "\t\tdel clean_mdf[name]\n",
    "\n",
    "# Step 2: Drop any rows with missing data in other columns\n",
    "clean_mdf = tdf.dropna()\n",
    "\n",
    "# Final state: Shape and missing data summary\n",
    "print(f\"Initial Shape: {clean_mdf.shape}\")\n",
    "print(f\"Initial Missing Data Summary:\\n{clean_mdf.isna().sum()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 8. Give brief explanations in your own words for any requested answers to the questions below."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 1. Use your ChatBot session to understand what `df.groupby(\"col1\")[\"col2\"].describe()` does and then demonstrate and explain this using a different example from the \"titanic\" data set other than what the ChatBot automatically provide for you."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The following code `df.groupby(\"col1\")[\"col2\"].describe()` groups all the data in `df` into rows based on the values in `col1`. By indexing `[\"col2\"]` and running `describe()`, 2 or more columns can be compared and analyzed.\n",
    "\n",
    "The following code shows that...\n",
    "1. Fewer women boarded the Titanic.\n",
    "2. Women on average payed more to board, with a little more variance when compared to men."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 206,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>count</th>\n",
       "      <th>mean</th>\n",
       "      <th>std</th>\n",
       "      <th>min</th>\n",
       "      <th>25%</th>\n",
       "      <th>50%</th>\n",
       "      <th>75%</th>\n",
       "      <th>max</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>sex</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>female</th>\n",
       "      <td>314.0</td>\n",
       "      <td>44.479818</td>\n",
       "      <td>57.997698</td>\n",
       "      <td>6.75</td>\n",
       "      <td>12.071875</td>\n",
       "      <td>23.0</td>\n",
       "      <td>55.00</td>\n",
       "      <td>512.3292</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>male</th>\n",
       "      <td>577.0</td>\n",
       "      <td>25.523893</td>\n",
       "      <td>43.138263</td>\n",
       "      <td>0.00</td>\n",
       "      <td>7.895800</td>\n",
       "      <td>10.5</td>\n",
       "      <td>26.55</td>\n",
       "      <td>512.3292</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        count       mean        std   min        25%   50%    75%       max\n",
       "sex                                                                        \n",
       "female  314.0  44.479818  57.997698  6.75  12.071875  23.0  55.00  512.3292\n",
       "male    577.0  25.523893  43.138263  0.00   7.895800  10.5  26.55  512.3292"
      ]
     },
     "execution_count": 206,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Load the Titanic dataset\n",
    "url = \"https://raw.githubusercontent.com/mwaskom/seaborn-data/master/titanic.csv\"\n",
    "df = pd.read_csv(url)\n",
    "\n",
    "# Group by 'sex' and describe the 'fare' column.\n",
    "df.groupby(\"sex\")[\"fare\"].describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 2. Assuming you've not yet removed missing values in the manner of question \"7\" above, `df.describe()` would have different values in the `count` value for different data columns depending on the missingness present in the original data.  Why do these capture something fundamentally different from the values in the `count` that result from doing something like `df.groupby(\"col1\")[\"col2\"].describe()`?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The key difference between the 2 expressions is that `df.describe()` counts the number of non-NaN entries in each row, while `df.groupby(\"col1\")[\"col2\"].describe()` counts the number of non-NaN entries in `col2` which pertain to `col1`. **For Example:** In the previous question, the expression counts how many men/women payed their fare separately."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 3. Intentionally introduce the following errors into your code and report your opinion as to whether it's easier to (a) work in a ChatBot session to fix the errors, or (b) use google to search for and fix errors: first share the errors you get in the ChatBot session and see if you can work with ChatBot to troubleshoot and fix the coding errors, and then see if you think a google search for the error provides the necessary toubleshooting help more quickly than ChatGPT."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**1. Forget to include `import pandas as pd` in your code**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It was easier to use ChatGPT."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**2. Mistype \"titanic.csv\" as \"titanics.csv\"**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ChatGPT understood that I may not have the file downloaded but it knew the full path since it was in the same session. Personally, I'd use the Internet to fix this error."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**3. Try to use a dataframe before it's been assigned into the variable**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Since the error is so specific to my code, ChatGPT was able to catch it. However, my code debugger in Visual Studio Code caught it first."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**4. Forget one of the parentheses somewhere the code**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Since the error is another SyntaxError, my debugger caught it first but ChatGPT was also helpful."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**5. Mistype one of the names of the chained functions with the code**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ChatGPT was more helpful than Google."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**6. Use a column name that's not in your data for the `groupby` and column selection.**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I pasted my code in a new ChatGPT session and I didn't understand the problem until I gave it the error from the console. However, I tried searching the error too and I believe I found the solution faster with the Internet."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**7. Forget to put the column name as a string in quotes for the `groupby` and column selection, and see if the ChatBot and google are still as helpful as they were for the previous question**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "My debugger was faster but ChatGPT was also helpful."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
