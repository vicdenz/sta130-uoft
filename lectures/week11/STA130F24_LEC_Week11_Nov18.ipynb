{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "9e1d847c",
   "metadata": {},
   "source": [
    "# STA130 LEC Week 11 (Nov 18)\n",
    "\n",
    "## Binary Classification Binary Decison Trees and Machine Learning\n",
    "\n",
    "*Didn't get to the code at the end of the last lecture, but that was a complex demonstration so let's just restart.*\n",
    "\n",
    "0. **Logistic Regression** \n",
    "\n",
    "    1. Makes **probability predictions** for **binary outcomes**\n",
    "    2. The **train-test** versus **statistical hypothesis testing and inference**\n",
    "    3. **Model Complexity** is number of **predictor variables** (and **interactions**)\n",
    "    4. **Generalization** versus **Overfitting**\n",
    "\n",
    "\n",
    "1. **Machine Learning** and **Regularization**\n",
    "\n",
    "    1. **Binary Classification Binary Decison Trees** \n",
    "        1. **Regularization Tuning Parameters** (or, technically, **stopping parameters**)\n",
    "        2. Decison Tree Construction AKA **Model Fitting**  \n",
    "        3. What are **Decison Trees**?\n",
    "            1. **Interactions**\n",
    "            2. **Feature Space** _partitions_\n",
    "            3. **Feature Importance**\n",
    "            4. **Partial Dependency Plots**\n",
    "\n",
    "    2. **Random Forests** (of **Bootstrapped Decision Trees**)\n",
    "\n",
    "\n",
    "2. **Prediction**, **thresholding**, and different **Metrics**\n",
    "\n",
    "\n",
    "3. **Self Evaluation \\#1: what's the correlation of your understanding versus the true of the following items?<br>AKA what's your 0%-100% (or, techically -100%-100%) understanding level for the following topics?**\n",
    "    1. Bootstrapped Confidence Intervals\n",
    "    2. \"Coin Flippling\" sampling distribution hypothesis testing for \"paired samples\"\n",
    "    3. Calculating p-values based on observed statistics and \"sampling distributions under the null\"\n",
    "    4. Correlation\n",
    "    5. The normal \"Simple Linear Regression\" model\n",
    "    6. Fitting Simple Linear Regression models\n",
    "    7. Making predictions from linear models\n",
    "    8. Using Simple Linear Regression to evaluate the evidence of association between two continue variables\n",
    "    9. Assessming the assumptions of Simple Linear Regression using residuals\n",
    "    10. Hypothesis testing for two unpaired samples using a permutation test (as opposed to hypothesis testing based on differences for \"paired samples\")\n",
    "    11. Hypothesis testing for two groups (unpaired samples) using indicator variables in Simple Linear Regression\n",
    "    12. \"Double\" bootstrap confidence intervals estimating difference parameters for two groups (unpaired samples)\n",
    "\n",
    "\n",
    "4. **Self Evaluation \\#2: what's the correlation of your understanding versus the true of the following items?<br>AKA what's your 0%-100% (or, techically -100%-100%) understanding level for the following topics?**\n",
    "\n",
    "    1. Multiple Linear Regression versus Simple Linear Regression\n",
    "    2. Binary indicator variables\n",
    "    3. Categorical variables\n",
    "    4. Interactions\n",
    "    5. Multicollinearity versus Statistical Inference\n",
    "    6. Multicollinearity versus Prediction\n",
    "    7. Logistic Regression\n",
    "    8. Classification veresus Regression\n",
    "    9. Machine Learning versus Statistical Inference\n",
    "    10. Classification Decision Trees versus Multiple Linear Regression\n",
    "    11. Classification Decision Trees versus Logistic Regression\n",
    "    12. Model Complexity and Overfitting\n",
    "    13. Model Complexity and Regularization Tuning Parameters\n",
    "    \n",
    "    \n",
    "5. **Student Lecture Summary**\n",
    "\n",
    "    \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4b6d264f",
   "metadata": {},
   "source": [
    "## 0. Restarting _Logistic Regression_ with _this new data set_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "faf3bf9a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd \n",
    "\n",
    "url = \"https://archive.ics.uci.edu/ml/machine-learning-databases/adult/adult.data\"\n",
    "\n",
    "column_names = [\"age\", \"workclass\", \"fnlwgt\", \"education\", \"education-num\", \n",
    "                \"marital-status\", \"occupation\", \"relationship\", \"race\", \"sex\", \n",
    "                \"capital-gain\", \"capital-loss\", \"hours-per-week\", \"native-country\", \n",
    "                \"income\"]\n",
    "data_raw = pd.read_csv(url, names=column_names, skipinitialspace=True)\n",
    "data_use = data_raw.copy()\n",
    "#data_use = data_use.drop(columns=['workclass', 'marital-status', 'occupation', \n",
    "#                                  'capital-gain', 'capital-loss', 'hours-per-week', \n",
    "#                                  'native-country', 'education-num', 'fnlwgt'])\n",
    "display(data_use.head(), data_use.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a915c7a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_use.income.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "063f8a59",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_use.education.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49c5c578",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_use.loc[data_use.education == 'Preschool', 'education'] = \"<=6th\"\n",
    "data_use.loc[data_use.education == '1st-4th', 'education'] = \"<=6th\"\n",
    "data_use.loc[data_use.education == '5th-6th', 'education'] = \"<=6th\"\n",
    "data_use.education.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f78a8bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_use.workclass.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba841278",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_use.loc[data_use.workclass == 'Without-pay', 'workclass'] = \"?\"\n",
    "data_use.loc[data_use.workclass == 'Never-worked', 'workclass'] = \"?\"\n",
    "data_use.workclass.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "09b60c66",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_use.occupation.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0767249d",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_use.loc[data_use.occupation == 'Armed-Forces', 'occupation'] = \"?\"\n",
    "data_use.occupation.value_counts()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1adacf46",
   "metadata": {},
   "outputs": [],
   "source": [
    "#data_use['workclass-occupation'] = data_use.workclass + \" \" + data_use.occupation\n",
    "#data_use['workclass-occupation'].value_counts()\n",
    "#for i,k in zip(data_use['workclassoccupation'].value_counts().index,data_use['workclass-occupation'].value_counts().values):\n",
    "#    print(i, k)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3828f035",
   "metadata": {},
   "source": [
    "## 0.2 The _train-test_ versus _statistical hypothesis testing and inference_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e582b31",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import model_selection\n",
    "import numpy as np\n",
    "\n",
    "np.random.seed(130)\n",
    "train, test = model_selection.train_test_split(data_use, train_size=0.8)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "406a40d7",
   "metadata": {},
   "source": [
    "## 0. Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34584e58",
   "metadata": {},
   "outputs": [],
   "source": [
    "import statsmodels.formula.api as smf\n",
    "\n",
    "formula = '''\n",
    "I((income=='>50K').astype(int)) ~ scale(age) + I(scale(age)**2) + I(scale(age)**3)\n",
    "                                + C(education, Treatment(reference='HS-grad'))\n",
    "'''\n",
    "logreg = smf.logit(formula, data=train)\n",
    "logreg_fit = logreg.fit()\n",
    "logreg_fit.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6306d022",
   "metadata": {},
   "source": [
    "## 0.1 Makes _probability predictions_ for _binary outcomes_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e47c89d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "np.corrcoef((train.income=='>50K'),(logreg_fit.predict(train)>0.5))#**2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66429d56",
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy import stats\n",
    "stats.spearmanr((train.income=='>50K'),(logreg_fit.predict(train)>0.5))#[0]**2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ae672b81",
   "metadata": {},
   "source": [
    "## 0.2 The _train-test_ versus _statistical hypothesis testing and inference_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a09b9b20",
   "metadata": {},
   "outputs": [],
   "source": [
    "((train.income=='>50K')==(logreg_fit.predict(train)>0.5)).sum()/train.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "43e7685a",
   "metadata": {},
   "outputs": [],
   "source": [
    "((test.income=='>50K')==(logreg_fit.predict(test)>0.5)).sum()/test.shape[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "243d7316",
   "metadata": {},
   "source": [
    "## 0.3 _Model Complexity_ is number of _predictor variables_ (and _interactions_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d9c5f778",
   "metadata": {},
   "outputs": [],
   "source": [
    "train[\"sex\"].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "78b3c86c",
   "metadata": {},
   "outputs": [],
   "source": [
    "train[\"marital-status\"].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "faf91043",
   "metadata": {},
   "outputs": [],
   "source": [
    "train.relationship.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "593bde62",
   "metadata": {},
   "outputs": [],
   "source": [
    "train.race.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aec59e3a",
   "metadata": {},
   "outputs": [],
   "source": [
    "formula = '''\n",
    "I((income=='>50K').astype(int)) ~ scale(age) + I(scale(age)**2) + I(scale(age)**3)\n",
    "                                + scale(Q(\"education-num\")) \n",
    "                                + C(education, Treatment(reference='HS-grad'))\n",
    "                                + C(Q(\"marital-status\"), Treatment(reference='Married-civ-spouse')) \n",
    "                                + C(relationship, Treatment(reference='Husband'))\n",
    "                                + C(sex, Treatment(reference='Male')) \n",
    "                                + C(race, Treatment(reference='White'))\n",
    "                                + C(workclass) + C(occupation)\n",
    "'''\n",
    "logreg = smf.logit(formula, data=train)\n",
    "logreg_fit = logreg.fit()\n",
    "logreg_fit.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "433c0418",
   "metadata": {},
   "source": [
    "## 0.4 **Generalization** versus **Overfitting**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3993497d",
   "metadata": {},
   "outputs": [],
   "source": [
    "((train.income=='>50K')==(logreg_fit.predict(train)>0.5)).sum()/train.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e1d4d55",
   "metadata": {},
   "outputs": [],
   "source": [
    "((test.income=='>50K')==(logreg_fit.predict(test)>0.5)).sum()/test.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b4f595e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "formula = '''\n",
    "I((income=='>50K').astype(int)) ~ scale(age) * I(scale(age)**2) \n",
    "                                * scale(Q(\"education-num\")) \n",
    "                                * C(race, Treatment(reference='White'))\n",
    "                                * C(sex, Treatment(reference='Male')) \n",
    "                                + C(education, Treatment(reference='HS-grad'))\n",
    "                                + C(Q(\"marital-status\"), Treatment(reference='Married-civ-spouse')) \n",
    "                                + C(relationship, Treatment(reference='Husband'))\n",
    "                                + C(workclass) + C(occupation)\n",
    "'''\n",
    "logreg = smf.logit(formula, data=train)\n",
    "logreg_fit = logreg.fit()\n",
    "logreg_fit.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6792c383",
   "metadata": {},
   "source": [
    "## 0.1 Makes _probability predictions_ for _binary outcomes_\n",
    "## 0.2 The _train-test_ versus _statistical hypothesis testing and inference_\n",
    "## 0.3 _Model Complexity_ is number of _predictor variables_ (and _interactions_)\n",
    "## 0.4 **Generalization** versus **Overfitting**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c878b0d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "((train.income=='>50K')==(logreg_fit.predict(train)>0.5)).sum()/train.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "454f64f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "((test.income=='>50K')==(logreg_fit.predict(test)>0.5)).sum()/test.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "93b5f415",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay\n",
    "cm_disp = ConfusionMatrixDisplay(\n",
    "    confusion_matrix((train.income=='>50K'), logreg_fit.predict(train)>0.5, \n",
    "    labels=[False, True]), display_labels=['<=50K','>50K'])\n",
    "_ = cm_disp.plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "133969c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "cm_disp = ConfusionMatrixDisplay(\n",
    "    confusion_matrix((test.income=='>50K'), logreg_fit.predict(test)>0.5, \n",
    "    labels=[False, True]), display_labels=['<=50K','>50K'])\n",
    "_ = cm_disp.plot()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8ea7d1f7",
   "metadata": {},
   "source": [
    "#### Accuracy\n",
    "Accuracy measures the proportion of true results (both true positives and true negatives) in the population.\n",
    "$$\\text{Accuracy} = \\frac{TP + TN}{TP + TN + FP + FN}$$\n",
    "\n",
    "#### Specificity (True Negative Rate)\n",
    " Specificity measures the proportion of actual negatives that are correctly identified.\n",
    "$$\\text{Specificity} = \\frac{TN}{TN + FP}$$\n",
    "\n",
    "#### Sensitivity (True Positive Rate)\n",
    "Sensitivity measures the proportion of actual positives that are correctly identified.\n",
    "$$\\text{Sensitivity} = \\frac{TP}{TP + FN}$$\n",
    "\n",
    "#### Precision (Positive Predictive Value)\n",
    "Precision measures the proportion of positive identifications that were actually correct.\n",
    "$$\\text{Precision} = \\frac{TP}{TP + FP}$$\n",
    "\n",
    "> - **Negative Predictive Value** is the \"negative\" version of **precision** $\\frac{TN}{TN + FN}$\n",
    "> - **False negative rates (FNR)** are defined to be the proportion of actually positive cases which are incorrectly identified (as false negatives) $TNR = TN/(TN+FP) = 1-FPR$\n",
    "> - **False positive rates (FPR)** are defined to be the proportion of actually negative cases which are incorrectly identified (as false positives) $TPR = TP/(TP+FN) = 1-FNR$\n",
    " \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "676b5d51",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score, recall_score, precision_score\n",
    "# in sklearn specificity is recall_score(y_true, y_pred, pos_label=0)\n",
    "# while sensitivity recall_score(y_true, y_pred, pos_label=1) is the default \n",
    "\n",
    "print(\"In sample (training) sensitivity\", recall_score(train.income=='>50K', logreg_fit.predict(train)>0.5, pos_label=True))\n",
    "print(\"Out of sample (testing) sensitivity\", recall_score(test.income=='>50K', logreg_fit.predict(test)>0.5, pos_label=True))\n",
    "print(\"In sample (training) specificity\", recall_score(train.income=='>50K', logreg_fit.predict(train)>0.5, pos_label=False))\n",
    "print(\"Out of sample (testing) specificity\", recall_score(test.income=='>50K', logreg_fit.predict(test)>0.5, pos_label=False))\n",
    "print(\"In sample (training) precision\", precision_score(train.income=='>50K', logreg_fit.predict(train)>0.5))\n",
    "print(\"Out of sample (testing) precision\", precision_score(test.income=='>50K', logreg_fit.predict(test)>0.5))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "35c7dc92",
   "metadata": {},
   "source": [
    "## 1. Machine Learning and Regularization\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22ef84a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = pd.get_dummies(train.iloc[:,:-1]).astype(float)\n",
    "X_test = X_train[:0].copy()\n",
    "X_test_tmp = pd.get_dummies(test.iloc[:,:-1])\n",
    "for col in X_test_tmp:\n",
    "    X_test[col] = X_test_tmp[col].astype(float)\n",
    "X_test = X_test.fillna(0.0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b9fbdc50",
   "metadata": {},
   "source": [
    "## 1.1 Binary Classification Binary Decison Trees"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26566af6",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier, plot_tree\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "clf = DecisionTreeClassifier(max_depth=15, random_state=42)\n",
    "clf.fit(X=X_train, y=(train.iloc[:,-1]=='>50K').astype(int))\n",
    "\n",
    "plt.figure(figsize=(10,5), dpi=200)\n",
    "plot_tree(clf, feature_names=X_train.columns.tolist(), \n",
    "          class_names=['<=50k','>50k'],\n",
    "          filled=True, rounded=True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9638ddbd",
   "metadata": {},
   "source": [
    "## 1.1.1. _Regularization Tuning Parameters_ (or, technically, _stopping parameters_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da08442e",
   "metadata": {},
   "outputs": [],
   "source": [
    "((train.income=='>50K')==clf.predict(X_train)).sum()/train.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "945dc3d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "((test.income=='>50K')==clf.predict(X_test)).sum()/test.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c01153dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "clf = DecisionTreeClassifier(max_depth=30, random_state=42)\n",
    "clf.fit(X=X_train, y=(train.iloc[:,-1]=='>50K').astype(int))\n",
    "\n",
    "plt.figure(figsize=(10,5), dpi=200)\n",
    "plot_tree(clf, feature_names=X_train.columns.tolist(), \n",
    "          class_names=['<=50k','>50k'],\n",
    "          filled=True, rounded=True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e57a1dfc",
   "metadata": {},
   "outputs": [],
   "source": [
    "((train.income=='>50K')==clf.predict(X_train)).sum()/train.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c9926778",
   "metadata": {},
   "outputs": [],
   "source": [
    "((test.income=='>50K')==clf.predict(X_test)).sum()/test.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b47be15",
   "metadata": {},
   "outputs": [],
   "source": [
    "DecisionTreeClassifier?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23aff1e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "clf = DecisionTreeClassifier(max_depth=30, random_state=42, \n",
    "                             min_samples_leaf=30, \n",
    "                             min_samples_split=100)\n",
    "clf.fit(X=X_train, y=(train.iloc[:,-1]=='>50K').astype(int))\n",
    "\n",
    "plt.figure(figsize=(10,5), dpi=200)\n",
    "plot_tree(clf, feature_names=X_train.columns.tolist(), \n",
    "          class_names=['<=50k','>50k'],\n",
    "          filled=True, rounded=True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4587202b",
   "metadata": {},
   "outputs": [],
   "source": [
    "((train.income=='>50K')==clf.predict(X_train)).sum()/train.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a1fe2ff2",
   "metadata": {},
   "outputs": [],
   "source": [
    "((test.income=='>50K')==clf.predict(X_test)).sum()/test.shape[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8b44b9cd",
   "metadata": {},
   "source": [
    "## 1.1.2. Decison Tree Construction AKA _Model Fitting_\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fde3d8e3",
   "metadata": {},
   "source": [
    "## 1.1.3. What are **Decison Trees**?\n",
    "\n",
    "### 1.1.3.1. Interactions\n",
    "\n",
    "![](https://www.researchgate.net/publication/280032275/figure/fig6/AS:340436318212124@1458177751589/An-example-population-decision-tree-and-a-personalized-decision-path-Panel-a-gives-the.png)\n",
    "\n",
    "### 1.1.3.2. Feature Space _partitions_\n",
    "\n",
    "![](https://res.cloudinary.com/dyd911kmh/image/upload/f_auto,q_auto:best/v1528907338/regression-tree_g8zxq5.png)\n",
    "\n",
    "### 1.1.3.3. Feature Importance\n",
    "\n",
    "### 1.1.3.4. Partial Dependency Plots\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e853bfb3",
   "metadata": {},
   "outputs": [],
   "source": [
    "#https://stackoverflow.com/questions/52771328/plotly-chart-not-showing-in-jupyter-notebook\n",
    "import plotly.offline as pyo\n",
    "# Set notebook mode to work in offline\n",
    "pyo.init_notebook_mode()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60b14662",
   "metadata": {},
   "outputs": [],
   "source": [
    "import plotly.express as px\n",
    "\n",
    "feature_importance_df = pd.DataFrame({\n",
    "    'Feature': X_train.columns.tolist(),\n",
    "    'Importance': clf.feature_importances_\n",
    "}).sort_values(by='Importance', ascending=False).reset_index()\n",
    "\n",
    "fig = px.bar(feature_importance_df[:20], y='Feature', x='Importance', \n",
    "             title='Feature Importance')\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec51d604",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.inspection import PartialDependenceDisplay\n",
    "\n",
    "# X_train.columns=='education-num' # 2\n",
    "_ = PartialDependenceDisplay.from_estimator(clf, X_train, (2,))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7cd0a7c8",
   "metadata": {},
   "source": [
    "## 1.2. **Random Forests** (of **Bootstrapped Decision Trees**)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6eb94fc7",
   "metadata": {},
   "outputs": [],
   "source": [
    "RandomForestClassifier?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60379406",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "# Fit 1000 Decision Trees with unlimited depth\n",
    "rfc = RandomForestClassifier(n_estimators=1000, random_state=1,\n",
    "                             min_samples_leaf=10, min_samples_split=30)\n",
    "rfc.fit(X=X_train, y=(train.iloc[:,-1]=='>50K').astype(int))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c8fe0bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "((train.income=='>50K')==rfc.predict(X_train)).sum()/train.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e10d975",
   "metadata": {},
   "outputs": [],
   "source": [
    "((test.income=='>50K')==rfc.predict(X_test)).sum()/test.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b6a89634",
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_importance_df = pd.DataFrame({\n",
    "    'Feature': X_train.columns.tolist(),\n",
    "    'Importance': rfc.feature_importances_\n",
    "}).sort_values(by='Importance', ascending=False).reset_index()\n",
    "\n",
    "fig = px.bar(feature_importance_df[:60], y='Feature', x='Importance', \n",
    "             title='Feature Importance',\n",
    "              width=800, height=1200)\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eabc9014",
   "metadata": {},
   "outputs": [],
   "source": [
    "_ = PartialDependenceDisplay.from_estimator(rfc, X_train, (2,))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "838f9963",
   "metadata": {},
   "outputs": [],
   "source": [
    "cm_disp = ConfusionMatrixDisplay(\n",
    "    confusion_matrix((train.income=='>50K'), clf.predict(X_train)==1.0, \n",
    "    labels=[False, True]), display_labels=['<=50K','>50K'])\n",
    "_ = cm_disp.plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "05107a81",
   "metadata": {},
   "outputs": [],
   "source": [
    "cm_disp = ConfusionMatrixDisplay(\n",
    "    confusion_matrix((train.income=='>50K'), rfc.predict(X_train)==1.0, \n",
    "    labels=[False, True]), display_labels=['<=50K','>50K'])\n",
    "_ = cm_disp.plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5968a9d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "cm_disp = ConfusionMatrixDisplay(\n",
    "    confusion_matrix((test.income=='>50K'), clf.predict(X_test)==1.0, \n",
    "    labels=[False, True]), display_labels=['<=50K','>50K'])\n",
    "_ = cm_disp.plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f456c66",
   "metadata": {},
   "outputs": [],
   "source": [
    "cm_disp = ConfusionMatrixDisplay(\n",
    "    confusion_matrix((test.income=='>50K'), rfc.predict(X_test)==1.0, \n",
    "    labels=[False, True]), display_labels=['<=50K','>50K'])\n",
    "_ = cm_disp.plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "76da3789",
   "metadata": {},
   "outputs": [],
   "source": [
    "cm_disp = ConfusionMatrixDisplay(\n",
    "    confusion_matrix((test.income=='>50K'), rfc.predict_proba(X_test)[:,1]>0.5, \n",
    "    labels=[False, True]), display_labels=['<=50K','>50K'])\n",
    "_ = cm_disp.plot()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "81d31e69",
   "metadata": {},
   "source": [
    "## 2. _Prediction_, _thresholding_, and different _Metrics_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d53fdd5c",
   "metadata": {},
   "outputs": [],
   "source": [
    "cm_disp = ConfusionMatrixDisplay(\n",
    "    confusion_matrix((test.income=='>50K'), rfc.predict_proba(X_test)[:,1]>0.8, \n",
    "    labels=[False, True]), display_labels=['<=50K','>50K'])\n",
    "_ = cm_disp.plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e0f9e20",
   "metadata": {},
   "outputs": [],
   "source": [
    "cm_disp = ConfusionMatrixDisplay(\n",
    "    confusion_matrix((test.income=='>50K'), rfc.predict_proba(X_test)[:,1]>0.2, \n",
    "    labels=[False, True]), display_labels=['<=50K','>50K'])\n",
    "_ = cm_disp.plot()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
